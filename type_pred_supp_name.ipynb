{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7035,
     "status": "ok",
     "timestamp": 1666849668121,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "pdrZ8gRDATiY",
    "outputId": "1fd723da-bab9-4158-e085-e4a48aa2db55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666849668122,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "YOACUCY2Ar1I",
    "outputId": "5e865c93-5e2a-403a-a5a0-c8071e800f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line (header) looks like this:\n",
      "\n",
      "\"category\",\"text\"\n",
      "\n",
      "Each data point looks like this:\n",
      "\n",
      "MFSMOBILERECHARGE,bengle sorif mama\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/content/drive/MyDrive/Colab Notebooks/type_pred_supp_name.csv\", 'r') as csvfile:\n",
    "    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n",
    "    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timau0NaBu-F"
   },
   "outputs": [],
   "source": [
    "NUM_WORDS = 500000\n",
    "EMBEDDING_DIM = 16\n",
    "MAXLEN = 20\n",
    "PADDING = 'post'\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "TRAINING_SPLIT = .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luvsg8MCDMZk"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    \"\"\"\n",
    "    Removes a list of stopwords\n",
    "    \n",
    "    Args:\n",
    "        sentence (string): sentence to remove the stopwords from\n",
    "    \n",
    "    Returns:\n",
    "        sentence (string): lowercase sentence without the stopwords\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def parse_data_from_file(filename):\n",
    "    \"\"\"\n",
    "    Extracts sentences and labels from a CSV file\n",
    "    \n",
    "    Args:\n",
    "        filename (string): path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        sentences, labels (list of string, list of string): tuple containing lists of sentences and labels\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            labels.append(row[0])\n",
    "            sentence = row[1]\n",
    "            sentence = remove_stopwords(sentence)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666849668122,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "cgQlzBoUKxe3",
    "outputId": "1a96eb0a-c02e-4d70-dc8e-f4c2e7bcb908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31592 sentences in the dataset.\n",
      "\n",
      "First sentence has 3 words (after removing stopwords).\n",
      "\n",
      "There are 31592 labels in the dataset.\n",
      "\n",
      "The first 5 labels are ['MFSMOBILERECHARGE', 'GROCERY', 'HARDWARE', 'HARDWARE', 'CLOTHSTORE']\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "sentences, labels = parse_data_from_file(\"/content/drive/MyDrive/Colab Notebooks/type_pred_supp_name.csv\")\n",
    "\n",
    "print(f\"There are {len(sentences)} sentences in the dataset.\\n\")\n",
    "print(f\"First sentence has {len(sentences[0].split())} words (after removing stopwords).\\n\")\n",
    "print(f\"There are {len(labels)} labels in the dataset.\\n\")\n",
    "print(f\"The first 5 labels are {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVxABLx4K0J8"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTIONS: train_val_split\n",
    "def train_val_split(sentences, labels, training_split):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of string): lower-cased sentences without stopwords\n",
    "        labels (list of string): list of labels\n",
    "        training split (float): proportion of the dataset to convert to include in the train set\n",
    "    \n",
    "    Returns:\n",
    "        train_sentences, validation_sentences, train_labels, validation_labels - lists containing the data splits\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Compute the number of sentences that will be used for training (should be an integer)\n",
    "    train_size = round(len(sentences)*training_split)\n",
    "\n",
    "    # Split the sentences and labels into train/validation splits\n",
    "    train_sentences = sentences[0:train_size]\n",
    "    train_labels = labels[0:train_size]\n",
    "\n",
    "    validation_sentences = sentences[train_size:]\n",
    "    validation_labels = labels[train_size:]\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return train_sentences, validation_sentences, train_labels, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666849668123,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "gxFDh94CLHeX",
    "outputId": "79f03f30-44ef-4282-ec53-68494490016a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26853 sentences for training.\n",
      "\n",
      "There are 26853 labels for training.\n",
      "\n",
      "There are 4739 sentences for validation.\n",
      "\n",
      "There are 4739 labels for validation.\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
    "\n",
    "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
    "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
    "print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n",
    "print(f\"There are {len(val_labels)} labels for validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNsHuVQrLLO4"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: fit_tokenizer\n",
    "def fit_tokenizer(train_sentences, num_words, oov_token):\n",
    "    \"\"\"\n",
    "    Instantiates the Tokenizer class on the training sentences\n",
    "    \n",
    "    Args:\n",
    "        train_sentences (list of string): lower-cased sentences without stopwords to be used for training\n",
    "        num_words (int) - number of words to keep when tokenizing\n",
    "        oov_token (string) - symbol for the out-of-vocabulary token\n",
    "    \n",
    "    Returns:\n",
    "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n",
    "    tokenizer = Tokenizer(num_words = num_words, oov_token=oov_token)\n",
    "    \n",
    "    # Fit the tokenizer to the training sentences\n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1884,
     "status": "ok",
     "timestamp": 1666849670743,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "VNkKm1OJLRbS",
    "outputId": "4e37f78e-6e6d-4377-95d6-fd08bb333605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 51410 words\n",
      "\n",
      "<OOV> token included in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "tokenizer = fit_tokenizer(train_sentences, NUM_WORDS, OOV_TOKEN)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(f\"Vocabulary contains {len(word_index)} words\\n\")\n",
    "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTm_H0hqLUpG"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: seq_and_pad\n",
    "def seq_and_pad(sentences, tokenizer, padding, maxlen):\n",
    "    \"\"\"\n",
    "    Generates an array of token sequences and pads them to the same length\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of string): list of sentences to tokenize and pad\n",
    "        tokenizer (object): Tokenizer instance containing the word-index dictionary\n",
    "        padding (string): type of padding to use\n",
    "        maxlen (int): maximum length of the token sequence\n",
    "    \n",
    "    Returns:\n",
    "        padded_sequences (array of int): tokenized sentences padded to the same length\n",
    "    \"\"\"    \n",
    "    ### START CODE HERE\n",
    "       \n",
    "    # Convert sentences to sequences\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    # Pad the sequences using the correct padding and maxlen\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1778,
     "status": "ok",
     "timestamp": 1666849672519,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "Yzkxe3JXLZTc",
    "outputId": "64ec8f0b-c097-4218-d658-85795632e1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded training sequences have shape: (26853, 20)\n",
      "\n",
      "Padded validation sequences have shape: (4739, 20)\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_padded_seq = seq_and_pad(train_sentences, tokenizer, PADDING, MAXLEN)\n",
    "val_padded_seq = seq_and_pad(val_sentences, tokenizer, PADDING, MAXLEN)\n",
    "\n",
    "print(f\"Padded training sequences have shape: {train_padded_seq.shape}\\n\")\n",
    "print(f\"Padded validation sequences have shape: {val_padded_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ipm6TUVpBji"
   },
   "outputs": [],
   "source": [
    "# categories into numerics\n",
    "categories=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LLCZawvLdki"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: tokenize_labels\n",
    "def tokenize_labels(all_labels, split_labels):\n",
    "    \"\"\"\n",
    "    Tokenizes the labels\n",
    "    \n",
    "    Args:\n",
    "        all_labels (list of string): labels to generate the word-index from\n",
    "        split_labels (list of string): labels to tokenize\n",
    "    \n",
    "    Returns:\n",
    "        label_seq_np (array of int): tokenized labels\n",
    "    \"\"\"\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Instantiate the Tokenizer (no additional arguments needed)\n",
    "    label_tokenizer = Tokenizer()\n",
    "    \n",
    "    # Fit the tokenizer on all the labels\n",
    "    label_tokenizer.fit_on_texts(all_labels)\n",
    "\n",
    "    global categories\n",
    "    categories = list(label_tokenizer.word_index)\n",
    "    \n",
    "    # Convert labels to sequences\n",
    "    label_seq = label_tokenizer.texts_to_sequences(split_labels) \n",
    "    \n",
    "    # Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n",
    "    label_seq_np = np.array(label_seq)-1\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return label_seq_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1666849674086,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "by_vFuCaLkUW",
    "outputId": "69ff1855-8b75-49ef-f96f-714cc0ce7b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are:  ['grocery', 'pharmacy', 'mfsmobilerecharge', 'electronics', 'clothstore', 'hardware', 'stationery']\n",
      "First 5 labels of the training set should look like this:\n",
      "[[2]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [4]]\n",
      "\n",
      "First 5 labels of the validation set should look like this:\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [3]\n",
      " [4]]\n",
      "\n",
      "Tokenized labels of the training set have shape: (26853, 1)\n",
      "\n",
      "Tokenized labels of the validation set have shape: (4739, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_label_seq = tokenize_labels(labels, train_labels)\n",
    "val_label_seq = tokenize_labels(labels, val_labels)\n",
    "\n",
    "print(\"Labels are: \", categories)\n",
    "\n",
    "print(f\"First 5 labels of the training set should look like this:\\n{train_label_seq[:5]}\\n\")\n",
    "print(f\"First 5 labels of the validation set should look like this:\\n{val_label_seq[:5]}\\n\")\n",
    "print(f\"Tokenized labels of the training set have shape: {train_label_seq.shape}\\n\")\n",
    "print(f\"Tokenized labels of the validation set have shape: {val_label_seq.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkaYz4axLo2X"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "def create_model(num_words, embedding_dim, maxlen):\n",
    "    \"\"\"\n",
    "    Creates a text classifier model\n",
    "    \n",
    "    Args:\n",
    "        num_words (int): size of the vocabulary for the Embedding layer input\n",
    "        embedding_dim (int): dimensionality of the Embedding layer output\n",
    "        maxlen (int): length of the input sequences\n",
    "    \n",
    "    Returns:\n",
    "        model (tf.keras Model): the text classifier model\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_seed(123)\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']) \n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485076,
     "status": "ok",
     "timestamp": 1666850159160,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "brXB7uSATs6j",
    "outputId": "4d4c98e8-c044-4aa7-fa7f-8f3f6d646ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "840/840 [==============================] - 102s 119ms/step - loss: 1.6867 - accuracy: 0.3694 - val_loss: 1.5465 - val_accuracy: 0.4263\n",
      "Epoch 2/5\n",
      "840/840 [==============================] - 97s 115ms/step - loss: 1.4290 - accuracy: 0.4700 - val_loss: 1.4133 - val_accuracy: 0.4815\n",
      "Epoch 3/5\n",
      "840/840 [==============================] - 95s 113ms/step - loss: 1.2250 - accuracy: 0.5585 - val_loss: 1.3732 - val_accuracy: 0.5083\n",
      "Epoch 4/5\n",
      "840/840 [==============================] - 95s 113ms/step - loss: 1.0608 - accuracy: 0.6391 - val_loss: 1.3910 - val_accuracy: 0.4919\n",
      "Epoch 5/5\n",
      "840/840 [==============================] - 96s 114ms/step - loss: 0.9162 - accuracy: 0.7014 - val_loss: 1.4373 - val_accuracy: 0.5016\n"
     ]
    }
   ],
   "source": [
    "model = create_model(NUM_WORDS, EMBEDDING_DIM, MAXLEN)\n",
    "\n",
    "history = model.fit(train_padded_seq, train_label_seq, epochs=5, validation_data=(val_padded_seq, val_label_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY0KvbNsUL9Y"
   },
   "outputs": [],
   "source": [
    "# def plot_graphs(history, metric):\n",
    "#     plt.plot(history.history[metric])\n",
    "#     plt.plot(history.history[f'val_{metric}'])\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.ylabel(metric)\n",
    "#     plt.legend([metric, f'val_{metric}'])\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_graphs(history, \"accuracy\")\n",
    "# plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1666852110037,
     "user": {
      "displayName": "Shithi Maitra",
      "userId": "01287562705842979191"
     },
     "user_tz": -360
    },
    "id": "uxIWu8SArjum",
    "outputId": "f0908986-3c38-4d42-e354-c29ee21564e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "nuralom vi: mfsmobilerecharge\n",
      "abba sutofoud ahnaf alahi yousuf aklas amir uddin amar amma anam bararifoud delwar abbu sunapur delwar caca home foysol sunapur jillu vai gas johir uncle dubai johir vaiya puranfoud kadir vai dukan kamal mutin mesab kibria caca bosir dada muslim sasa parul akther reja gusainpur rohim sunapur rubel sunapur shabuddin agfoud purbo shale ahmod suto vai simul vai sunapur solima fufu somir vai agfoud sorif vai sunapur sultana fufu taher vai birdol bazar taj uddin agfoud possim yahya abdulmalik agfud: grocery\n",
      "all max surgical mask office ibne sina prodip da neela queen plus a neucare nazmul vai rafi pharmacy thai dealer rayhan v times fashion mask cotton whisper china: pharmacy\n",
      "alamin gas baccu vai billal vai raju vai shakil ssv utpal da s: grocery\n",
      "আলামিন সিরাজকান্দি: grocery\n",
      "rupchanda: grocery\n",
      "রফিক মামা: grocery\n",
      "mami: grocery\n",
      "ma mainuddin kaka: mfsmobilerecharge\n",
      "সাদ্দাম হোসাইন: pharmacy\n",
      "baboo vai kl: grocery\n",
      "anto: grocery\n",
      "আন্টির রিন আদায় দুলাভাই ইলিয়াছ নোমান ভাই ওয়াকস্প: grocery\n",
      "চঞ্চল দাদা: electronics\n",
      "টুকিটাকি ষ্টোর: grocery\n",
      "মোঃ মাসুদ প্রাধান বাড়ি: grocery\n",
      "ডাবলু ভাই নিতু সেলিম: grocery\n",
      "modon morga: grocery\n",
      "azahar kaka: grocery\n",
      "ma ma motaleb vai nur amin vai bm upen ka: mfsmobilerecharge\n",
      "ইউসুফ এন্ড ব্রাদার্স: grocery\n",
      "apu mastir dr fatima: pharmacy\n",
      "raja sir dzn ruman বাসার বাজার নগদ কিনা: mfsmobilerecharge\n",
      "আলোম মামা ফিরোজ আকাশ মা ইলেকট্রনিক্স রবিউল ভাই মোড়লগঞ্জ: grocery\n",
      "mশরিফ হামদ্দ squar ziska আজম ভাই একম তানভীরএরিস্টোফামা হেলিম বড়পারা: pharmacy\n",
      "জাকিরুল ভাবি: electronics\n",
      "sajib: grocery\n",
      "new vai vai brkari raion মিয়া টেডাস ভোজেসসর বাজার মেসাস কোতোয়াল এন্টারপ্রাইজ রাজিব মেসাস খলিল টেডাস বুড়ির হাট মেসাস বাসার হাডওয়ার সুজন পাল ভোজেস্বর বাজার: clothstore\n",
      "alamin koiradanga: grocery\n",
      "ashik friend gp khalek maa ma personal moushumi parsonal nur muhammad mama saidul personal new shahidul nd: electronics\n",
      "anar notonbazar: grocery\n",
      "rony ro: grocery\n",
      "best one crown com globe com green com ibnesina com ohcl com permasiya com rephco com sharif com thehan com ziska com: pharmacy\n",
      "kamal vai tv vision bedud vai: electronics\n",
      "ropik sharif home appliance: grocery\n",
      "nayem ahamed: mfsmobilerecharge\n",
      "কামাল কুতুবুদ্দিন নিখিল মাসুম শরীফ: grocery\n",
      "dama এিনাথ ভান্ডার পুরান বাজার কাতিক সাহা গৌতম ঝলক ফিজাপ জনতা লবন বগুড়া গি বিকাশ বাবু সুখরন্জন রায় পুরান বাজার সুমন বসুন্ধরা সেবক: grocery\n",
      "acme laboratories ad ayurbedic a alim vi ad ayurbedic laboratorys ltd adruk pharmaceutical bioneed sakil bio pharma comfort diaper delta pharma limited b kash euro pharma genial unani laboratories gk uro pharma khokanvi hamdord laboratories majbah hamja laboratories kamrul hasan kemico pharmaceuticals rubel mansons laboratories navana pharmaceuticals neuron laboratories renata renata limited anis sanj bangladesh sharif pharmaceuticals skf sotmal ripon strip all jahangir vi sunman birdem pharma team pharmaceuticals সাফায়াত thai diaper raihan unimed আটার হিসাব বসুন্ধরা ডায়াপার মিজান মোদির দোকান: pharmacy\n",
      "aci zia acme parma addin pharma akas sampol albion aristo pharma asif staf beximco pharma biopharma bms delta par delta pharma debion expiary drug sr khul fatema suston gen vison jun glove parma hamdard helh care heraz sumon medcl ibnesina parma incepta kamrul uncal khaja stor monir sanitari opsonin cardiac opsonin parma phsrmasia popular selim tils ctg sensudyn usa servear parma skf gena smc sojeb sun molla omor thai apu thai pamp hosen unimed amirul ziska parma: pharmacy\n",
      "jahid good lucks paper nozrul flexiload gp rasel khata sujon avinandan khata: mfsmobilerecharge\n",
      "abu shojib holdi asraful morij balubazar piaj mulbi: grocery\n",
      "dr harun warruk dr samsul taralia dr sonjoy w station mamun vai medilab polas medical bolsi war jonnsaba w station shad: pharmacy\n",
      "mohasin mobil rajue display tlue msmu: grocery\n",
      "ফারুক বম: grocery\n",
      "অনির্বাণ ল্যাবরেটরীজ ইবনে সিনা ফার্মাসিউটিক্যাল কুমুদিনী ফার্মাসিটিক্যাল নাভানা ফার্মাসিউটিক্যাল শরিফ ফার্মা শাহ আমানত হামদর্দ: pharmacy\n",
      "acme company adhunik pharma arzu diaper bul buli pharma edruk company hamdard compani health care pharma ikramul vai solar unani team saddam compani: pharmacy\n",
      "rasel vai sohan vai: mfsmobilerecharge\n",
      "ইকরা স্টোর: grocery\n",
      "এনাম সদাগর খথিজা আন্টি গিরিল আলা জাহিদ আংকেল মোতালেব মোতালেব সদাগর রাচেল মা রাসেল মা সন্জয় ডাকতার সবজি খালা হোসেন বাই হোসেন ভাই: grocery\n",
      "ripon bhai: grocery\n",
      "abdur razzak radiant abul kalam azad healthcare alamgir hossain vai square anwar hossain beacon arif vai sk f belal vai popular dipok vai beximco drug international khairuzzaman fazlul haque ibn sina hamdard saidur hasan vai beximco bl jamil hossain square consumer lablu vai gp incepta maruf vai smc mr mask poly gloves supplier md abdul kader jayson md abdul mannan aristopharma md afzal hossain aci md elias ali general md jashim uddin acme md khalidur rahman pharmasia md mahmudul hasan md rashedul idlam monir hossain opsonin monir vai navana nuvista shamsuzzoha rakibul islam biopharma rashedul islam orion savlon product biplob tofazzal hossain renata unimed unihealth shahadat ziska shamim: pharmacy\n",
      "shovo cha ইসলামীয়া জয়পুরহাট দুলাল ভাই বানিয়াপাড়া নজরুল মস্তফা বল্টু দাদা জয়পুর হাট বিডি জয়পুরহাট বিয়াই: grocery\n",
      "habiba vaby আলল্পার মা কলেজ পাড়া গ্ৰাহক মালেকা ইকবাল এর মা দীন ইসলাম মুকুল ভাই সবুজ ভাই ফার্মেসি: pharmacy\n",
      "afdula ca dukan alom bai dim b dolor fid gavi salam pati: grocery\n",
      "masud azmir stationery tarif: pharmacy\n",
      "মেরিজ: grocery\n",
      "anis tazol md oahidul islam personal zakat: pharmacy\n",
      "শ্যামল দাস: grocery\n",
      "alaur rahman lalvaisab amma ataur vai boss gura caca habib ar bow ha ismail jamal mamun kaundar m husain vai monir opsonin moni vai parsunal parbotpur hujur rofik caa sahin vai o sumi k borar umayer ar mama গরু জাহেদ ভাগনা তরিকুল নিজের সাদাপাথর: grocery\n",
      "saiful: grocery\n",
      "আবুবক্কর ভাই সাউদা আয়নাল ভাই পলি কামাল৷৷৷৷৷৷৷ রতন নয়ন নাজমুন নুরা পলি বাবুল সিকদার সিরাজ৷ শাহিন রুপালী: grocery\n",
      "aci advent pharma ltd: pharmacy\n",
      "abol abol cng aertel akota asad banlalenk benson berac njo geramin hossain koran maje r boda metador morjena robi আহমদ নুর আারমান নেভী পান বুডা সাতকানিয়া মেরীস: grocery\n",
      "অনিক আব্দুল খালেক হাসপাতাল: grocery\n",
      "halal vi bhola kamall vi polli mannan vi rumman: pharmacy\n",
      "murad tushar bhai: electronics\n",
      " shahabuddin: grocery\n",
      "আব্বদুর রাজ্জাক আলী সও খলিল সও ছালাম সও তীর কো নাজিম ষ্টোর স্টার শীপ: grocery\n",
      "beauty lavoni art mollik mama: electronics\n",
      "ad din jahangir ajij opsonin najir: grocery\n",
      "ma babar doya: grocery\n",
      "খরজ হিসাব গৌর: grocery\n",
      "bowma আলাই মামা: grocery\n",
      "আপু জনছন এস আর তারিকু টেংক s r নেছলে সুপার ভাইজার নেয়ামোত পুস্টি ছলটেছ এস আর ফকসেন এস আর রাকী ইনিলিভার এস আর ইনডী রাজন নেছলে কফি মেকার রুপচাঁদা সোয়াবিন এস আর সেনটারফুট এস আর সৌদি য় বেকারী জানেআলম: grocery\n",
      "চঞ্চল মিরাজ রোমান: electronics\n",
      "amir kaka cxcx hasan munsi: grocery\n",
      "my rocket: grocery\n",
      "borhan joyita pcs jafor bag house nasim mama nazim ind orna wahid parjowar agency raju kansat ripon islampur torikul gamcha zabid অনন ফ্যাশন অরবিট মদিনা ডাইড পপলিন কামাল সরকার ড়িসেন্ড সন্ধান লুঙ্গি হাজী ওসমান: clothstore\n",
      "জহির রায়হান: grocery\n",
      "babu dula: mfsmobilerecharge\n",
      "razzak bl: mfsmobilerecharge\n",
      "abu bokkor saplayr alif mur amjaz vaijan s badsha shahin uttara elias hafijul vai bari happy jorna kala taleb mahabul islam mobidul vai modhu r ma modhur ma moshiur mn mosiur ari moynul sahin sonjit sujon bari sukaru sumon saidar tuhin আব্দুল খালেক আস্থা সমবায় সমিতি: mfsmobilerecharge\n",
      "stm international ltd: electronics\n",
      "ইট মাহাজন: grocery\n",
      "alamin: grocery\n",
      "super star blink wife আব্দুল বাতেন খলিল: mfsmobilerecharge\n",
      "smart মেহেদি কসমেটিক্স কামাল গার্মেন্স পার্টি জসিম ভাই কালি গন্জ পান্জাবি নুর মনি মক্কা ক্লথ সুমন সিফাত হুসিয়ারি হাফিজুর রহমান এন্ড সন্স: clothstore\n",
      "মওলানা মেডিকেল মোঃআ রহিম মোল্লা রাজ্জাক মেডিকেল: pharmacy\n",
      "mutabbir caca: grocery\n",
      "sobuj ali: electronics\n",
      "ভি আই পি টেইলাস: pharmacy\n",
      "নাফকো ফার্মা লিঃ: pharmacy\n",
      "bareq vai udaypur sojib kaka hatkhali: grocery\n",
      "একমি আলিম সুমন: pharmacy\n",
      "abbu adlib brac uncle ebl raju sufi old zihad dibe sufi zihad dibe venice rent: grocery\n",
      "best bkash: mfsmobilerecharge\n",
      "আকতার মহাজন আনোয়ার মহাজন আবুল যশাই এমদাদুল মহাজন জলিল ইনডিয়ান মহাজন তানভীর স্টোর তালেব মহাজন নজরুল গার্মেন্টস নবী নেওয়াজ নাসিম গার্মেন্টস বেলাল দিনাজপুর মেসার্স ন্যাশনাল বস্ত্রালয় মোওালেব মহাজন সাইফুদদৌলা সাইফুল মহাজন হারেজ: clothstore\n",
      "সেলিনা: grocery\n",
      "abba aristocrat balughat gias mama led milon moteen vhaiya stf manikdi babu v miyako tp nirmol da: electronics\n",
      "\n",
      "[[False  True False ... False  True False]\n",
      " [False  True False ... False  True False]\n",
      " [False False  True ... False False False]\n",
      " ...\n",
      " [False False False ...  True False False]\n",
      " [ True False False ... False False False]\n",
      " [False False False ... False False  True]]\n"
     ]
    }
   ],
   "source": [
    "# probabilies against all classes for selective validation data\n",
    "pred_probabilities=model.predict(val_padded_seq[0:100, :])\n",
    "\n",
    "# predictions against selective validation data\n",
    "pred_classes=[categories[item] for item in np.argmax(pred_probabilities, axis=1)]\n",
    "val_shop_names=val_sentences[0:100]\n",
    "\n",
    "for i in range(0, len(val_shop_names)): \n",
    "  print(val_shop_names[i]+ \": \"+pred_classes[i])\n",
    "\n",
    "print()\n",
    "\n",
    "# if predictions match\n",
    "print(np.argmax(pred_probabilities, axis=1)==(np.squeeze(val_label_seq[0:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOzSKagLFPz8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
