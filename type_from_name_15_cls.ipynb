{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdrZ8gRDATiY","outputId":"1c6ea2f8-c13b-457e-8f83-65774f126497","executionInfo":{"status":"ok","timestamp":1667878040542,"user_tz":-360,"elapsed":554888,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import io\n","import csv\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/Colab Notebooks/type_from_name_15_cls.csv\", 'r') as csvfile:\n","    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n","    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOACUCY2Ar1I","outputId":"8414abb5-bd02-4cec-8ace-7cb3942b9495","executionInfo":{"status":"ok","timestamp":1667878042173,"user_tz":-360,"elapsed":1634,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["First line (header) looks like this:\n","\n","\"category\",\"text\"\n","\n","Each data point looks like this:\n","\n","electronics,ইলেকট্রনিক্স \n","\n"]}]},{"cell_type":"code","source":["NUM_WORDS = 700000\n","EMBEDDING_DIM = 16\n","MAXLEN = 5\n","PADDING = 'post'\n","OOV_TOKEN = \"<OOV>\"\n","TRAINING_SPLIT = .85"],"metadata":{"id":"timau0NaBu-F","executionInfo":{"status":"ok","timestamp":1667878042174,"user_tz":-360,"elapsed":9,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def remove_stopwords(sentence):\n","    \"\"\"\n","    Removes a list of stopwords\n","    \n","    Args:\n","        sentence (string): sentence to remove the stopwords from\n","    \n","    Returns:\n","        sentence (string): lowercase sentence without the stopwords\n","    \"\"\"\n","    pass\n","\n","    return sentence\n","\n","\n","def parse_data_from_file(filename):\n","    \"\"\"\n","    Extracts sentences and labels from a CSV file\n","    \n","    Args:\n","        filename (string): path to the CSV file\n","    \n","    Returns:\n","        sentences, labels (list of string, list of string): tuple containing lists of sentences and labels\n","    \"\"\"\n","    sentences = []\n","    labels = []\n","    with open(filename, 'r') as csvfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","        next(reader)\n","        for row in reader:\n","            labels.append(row[0])\n","            sentence = row[1]\n","            sentence = remove_stopwords(sentence)\n","            sentences.append(sentence)\n","\n","    return sentences, labels"],"metadata":{"id":"Luvsg8MCDMZk","executionInfo":{"status":"ok","timestamp":1667878042175,"user_tz":-360,"elapsed":9,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Test the functions\n","sentences, labels = parse_data_from_file(\"/content/drive/MyDrive/Colab Notebooks/type_from_name_15_cls.csv\")\n","\n","print(f\"There are {len(sentences)} sentences in the dataset.\\n\")\n","print(f\"First sentence has {len(sentences[0].split())} words (after removing stopwords).\\n\")\n","print(f\"There are {len(labels)} labels in the dataset.\\n\")\n","print(f\"The first 5 labels are {labels[:5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgQlzBoUKxe3","outputId":"72922658-063a-466c-951c-2178a4bb03ec","executionInfo":{"status":"ok","timestamp":1667878043311,"user_tz":-360,"elapsed":1144,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 280000 sentences in the dataset.\n","\n","First sentence has 1 words (after removing stopwords).\n","\n","There are 280000 labels in the dataset.\n","\n","The first 5 labels are ['electronics', 'mfsmobilerecharge', 'pharmacy', 'cosmetics', 'electronics']\n"]}]},{"cell_type":"code","source":["# GRADED FUNCTIONS: train_val_split\n","def train_val_split(sentences, labels, training_split):\n","    \"\"\"\n","    Splits the dataset into training and validation sets\n","    \n","    Args:\n","        sentences (list of string): lower-cased sentences without stopwords\n","        labels (list of string): list of labels\n","        training split (float): proportion of the dataset to convert to include in the train set\n","    \n","    Returns:\n","        train_sentences, validation_sentences, train_labels, validation_labels - lists containing the data splits\n","    \"\"\"\n","    \n","    ### START CODE HERE\n","    \n","    # Compute the number of sentences that will be used for training (should be an integer)\n","    train_size = round(len(sentences)*training_split)\n","\n","    # Split the sentences and labels into train/validation splits\n","    train_sentences = sentences[0:train_size]\n","    train_labels = labels[0:train_size]\n","\n","    validation_sentences = sentences[train_size:]\n","    validation_labels = labels[train_size:]\n","    \n","    ### END CODE HERE\n","    \n","    return train_sentences, validation_sentences, train_labels, validation_labels"],"metadata":{"id":"kVxABLx4K0J8","executionInfo":{"status":"ok","timestamp":1667878043312,"user_tz":-360,"elapsed":15,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Test your function\n","train_sentences, val_sentences, train_labels, val_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n","\n","print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n","print(f\"There are {len(train_labels)} labels for training.\\n\")\n","print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n","print(f\"There are {len(val_labels)} labels for validation.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxFDh94CLHeX","outputId":"28f3927d-4b7f-4e0e-dab7-5e164bf7d3b7","executionInfo":{"status":"ok","timestamp":1667878043312,"user_tz":-360,"elapsed":13,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 238000 sentences for training.\n","\n","There are 238000 labels for training.\n","\n","There are 42000 sentences for validation.\n","\n","There are 42000 labels for validation.\n"]}]},{"cell_type":"code","source":["# GRADED FUNCTION: fit_tokenizer\n","def fit_tokenizer(train_sentences, num_words, oov_token):\n","    \"\"\"\n","    Instantiates the Tokenizer class on the training sentences\n","    \n","    Args:\n","        train_sentences (list of string): lower-cased sentences without stopwords to be used for training\n","        num_words (int) - number of words to keep when tokenizing\n","        oov_token (string) - symbol for the out-of-vocabulary token\n","    \n","    Returns:\n","        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n","    \"\"\"\n","    \n","    ### START CODE HERE\n","    \n","    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n","    tokenizer = Tokenizer(num_words = num_words, oov_token=oov_token)\n","    \n","    # Fit the tokenizer to the training sentences\n","    tokenizer.fit_on_texts(train_sentences)\n","    \n","    ### END CODE HERE\n","    \n","    return tokenizer"],"metadata":{"id":"vNsHuVQrLLO4","executionInfo":{"status":"ok","timestamp":1667878043313,"user_tz":-360,"elapsed":9,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Test your function\n","tokenizer = fit_tokenizer(train_sentences, NUM_WORDS, OOV_TOKEN)\n","word_index = tokenizer.word_index\n","\n","print(f\"Vocabulary contains {len(word_index)} words\\n\")\n","print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNkKm1OJLRbS","outputId":"7d6e2fc0-0e30-4861-f562-8d7073960228","executionInfo":{"status":"ok","timestamp":1667878045855,"user_tz":-360,"elapsed":2549,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary contains 49094 words\n","\n","<OOV> token included in vocabulary\n"]}]},{"cell_type":"code","source":["# GRADED FUNCTION: seq_and_pad\n","def seq_and_pad(sentences, tokenizer, padding, maxlen):\n","    \"\"\"\n","    Generates an array of token sequences and pads them to the same length\n","    \n","    Args:\n","        sentences (list of string): list of sentences to tokenize and pad\n","        tokenizer (object): Tokenizer instance containing the word-index dictionary\n","        padding (string): type of padding to use\n","        maxlen (int): maximum length of the token sequence\n","    \n","    Returns:\n","        padded_sequences (array of int): tokenized sentences padded to the same length\n","    \"\"\"    \n","    ### START CODE HERE\n","       \n","    # Convert sentences to sequences\n","    sequences = tokenizer.texts_to_sequences(sentences)\n","    \n","    # Pad the sequences using the correct padding and maxlen\n","    padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding)\n","    \n","    ### END CODE HERE\n","    \n","    return padded_sequences"],"metadata":{"id":"RTm_H0hqLUpG","executionInfo":{"status":"ok","timestamp":1667878045856,"user_tz":-360,"elapsed":5,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Test your function\n","train_padded_seq = seq_and_pad(train_sentences, tokenizer, PADDING, MAXLEN)\n","val_padded_seq = seq_and_pad(val_sentences, tokenizer, PADDING, MAXLEN)\n","\n","print(f\"Padded training sequences have shape: {train_padded_seq.shape}\\n\")\n","print(f\"Padded validation sequences have shape: {val_padded_seq.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yzkxe3JXLZTc","outputId":"c1ccbff3-c435-4ff1-b898-f10fd67e6360","executionInfo":{"status":"ok","timestamp":1667878049950,"user_tz":-360,"elapsed":4098,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Padded training sequences have shape: (238000, 5)\n","\n","Padded validation sequences have shape: (42000, 5)\n"]}]},{"cell_type":"code","source":["# categories into numerics\n","categories=list()"],"metadata":{"id":"5ipm6TUVpBji","executionInfo":{"status":"ok","timestamp":1667878049950,"user_tz":-360,"elapsed":14,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# GRADED FUNCTION: tokenize_labels\n","def tokenize_labels(all_labels, split_labels):\n","    \"\"\"\n","    Tokenizes the labels\n","    \n","    Args:\n","        all_labels (list of string): labels to generate the word-index from\n","        split_labels (list of string): labels to tokenize\n","    \n","    Returns:\n","        label_seq_np (array of int): tokenized labels\n","    \"\"\"\n","    ### START CODE HERE\n","    \n","    # Instantiate the Tokenizer (no additional arguments needed)\n","    label_tokenizer = Tokenizer()\n","    \n","    # Fit the tokenizer on all the labels\n","    label_tokenizer.fit_on_texts(all_labels)\n","\n","    global categories\n","    categories = list(label_tokenizer.word_index)\n","    \n","    # Convert labels to sequences\n","    label_seq = label_tokenizer.texts_to_sequences(split_labels) \n","    \n","    # Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n","    label_seq_np = np.array(label_seq)-1\n","    \n","    ### END CODE HERE\n","    \n","    return label_seq_np"],"metadata":{"id":"8LLCZawvLdki","executionInfo":{"status":"ok","timestamp":1667878049950,"user_tz":-360,"elapsed":13,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Test your function\n","train_label_seq = tokenize_labels(labels, train_labels)\n","val_label_seq = tokenize_labels(labels, val_labels)\n","\n","print(\"Labels are: \", categories)\n","\n","print(f\"First 5 labels of the training set should look like this:\\n{train_label_seq[:5]}\\n\")\n","print(f\"First 5 labels of the validation set should look like this:\\n{val_label_seq[:5]}\\n\")\n","print(f\"Tokenized labels of the training set have shape: {train_label_seq.shape}\\n\")\n","print(f\"Tokenized labels of the validation set have shape: {val_label_seq.shape}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"by_vFuCaLkUW","outputId":"20e346b2-7b64-4e55-a5a8-b83ea8971649","executionInfo":{"status":"ok","timestamp":1667878056770,"user_tz":-360,"elapsed":6833,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels are:  ['grocery', 'distributororwholesale', 'mfsmobilerecharge', 'pharmacy', 'electronics', 'clothstore', 'hardware', 'agriculture', 'bakeryandconfectionery', 'motorrepair', 'stationery', 'cosmetics', 'tailors', 'householdandfurniture', 'shoestore']\n","First 5 labels of the training set should look like this:\n","[[ 4]\n"," [ 2]\n"," [ 3]\n"," [11]\n"," [ 4]]\n","\n","First 5 labels of the validation set should look like this:\n","[[0]\n"," [7]\n"," [1]\n"," [0]\n"," [2]]\n","\n","Tokenized labels of the training set have shape: (238000, 1)\n","\n","Tokenized labels of the validation set have shape: (42000, 1)\n","\n"]}]},{"cell_type":"code","source":["# GRADED FUNCTION: create_model\n","def create_model(num_words, embedding_dim, maxlen):\n","    \"\"\"\n","    Creates a text classifier model\n","    \n","    Args:\n","        num_words (int): size of the vocabulary for the Embedding layer input\n","        embedding_dim (int): dimensionality of the Embedding layer output\n","        maxlen (int): length of the input sequences\n","    \n","    Returns:\n","        model (tf.keras Model): the text classifier model\n","    \"\"\"\n","    \n","    tf.random.set_seed(123)\n","    \n","    ### START CODE HERE\n","    \n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n","        tf.keras.layers.GlobalAveragePooling1D(),\n","        tf.keras.layers.Dense(16, activation='relu'),\n","        tf.keras.layers.Dense(15, activation='softmax')\n","    ])\n","    \n","    model.compile(loss='sparse_categorical_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy']) \n","\n","    ### END CODE HERE\n","\n","    return model\n"],"metadata":{"id":"rkaYz4axLo2X","executionInfo":{"status":"ok","timestamp":1667878056771,"user_tz":-360,"elapsed":30,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model = create_model(NUM_WORDS, EMBEDDING_DIM, MAXLEN)\n","\n","history = model.fit(train_padded_seq, train_label_seq, epochs=3, validation_data=(val_padded_seq, val_label_seq))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brXB7uSATs6j","outputId":"ebfd19e4-da66-4a5a-fd01-87b0e55d855e","executionInfo":{"status":"ok","timestamp":1667880665992,"user_tz":-360,"elapsed":2609249,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","7438/7438 [==============================] - 873s 117ms/step - loss: 1.6046 - accuracy: 0.5064 - val_loss: 1.4154 - val_accuracy: 0.5622\n","Epoch 2/3\n","7438/7438 [==============================] - 867s 117ms/step - loss: 1.3208 - accuracy: 0.5965 - val_loss: 1.3799 - val_accuracy: 0.5751\n","Epoch 3/3\n","7438/7438 [==============================] - 869s 117ms/step - loss: 1.2281 - accuracy: 0.6264 - val_loss: 1.3889 - val_accuracy: 0.5745\n"]}]},{"cell_type":"code","source":["# def plot_graphs(history, metric):\n","#     plt.plot(history.history[metric])\n","#     plt.plot(history.history[f'val_{metric}'])\n","#     plt.xlabel(\"Epochs\")\n","#     plt.ylabel(metric)\n","#     plt.legend([metric, f'val_{metric}'])\n","#     plt.show()\n","    \n","# plot_graphs(history, \"accuracy\")\n","# plot_graphs(history, \"loss\")"],"metadata":{"id":"zY0KvbNsUL9Y","executionInfo":{"status":"ok","timestamp":1667880665993,"user_tz":-360,"elapsed":23,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# probabilies against all classes for selective validation data\n","pred_probabilities=model.predict(val_padded_seq[0:100, :])\n","\n","# predictions against selective validation data\n","pred_classes=[categories[item] for item in np.argmax(pred_probabilities, axis=1)]\n","val_shop_names=val_sentences[0:100]\n","\n","for i in range(0, len(val_shop_names)): \n","  print(val_shop_names[i]+ \": \"+pred_classes[i])\n","\n","print()\n","\n","# if predictions match\n","print(np.argmax(pred_probabilities, axis=1)==val_label_seq[0:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxIWu8SArjum","executionInfo":{"status":"ok","timestamp":1667880666666,"user_tz":-360,"elapsed":680,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}},"outputId":"dab3849f-46ff-4898-fe4e-feb6732ead37"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 3ms/step\n","নয়ন ষ্টে র : grocery\n","banana shop : distributororwholesale\n","denim corp : distributororwholesale\n","সৈকত স্টোর : grocery\n","store : grocery\n","cosmetics telecom : mfsmobilerecharge\n","হাসান স্টোর সাওল বাজার : grocery\n","সুজ : shoestore\n","মায়া ঔষধ বিতান নগরের হাট : pharmacy\n","স্টোর : grocery\n","m didar telecom : mfsmobilerecharge\n","pharma : pharmacy\n","হোসেন : grocery\n","কসমেটিক্স : cosmetics\n","ডিজিটাল স্টুডিও : electronics\n","shatata store : grocery\n","হিসাব ২০২০ : distributororwholesale\n","অন্তর এন্টার প্রাইজ : hardware\n","ইলেকট্রনিক্স : electronics\n","সাদী টেলিকম এন্ড সফটওয়্যার পয়েন্ট : electronics\n","হাদায়া : grocery\n","টেলিকম : mfsmobilerecharge\n","এন্টার প্রাইজ : distributororwholesale\n","ইত্যাদি : clothstore\n","টেইলার্স : tailors\n","ট্রেডার্স ছমির মুন্সির হাট : distributororwholesale\n","আজিজ ষ্টোর : grocery\n","মদিনা ট্রেডার্স : distributororwholesale\n","টি হক লিমিটেড : distributororwholesale\n","feni : distributororwholesale\n","store : grocery\n","zone : electronics\n","টেলিকম এন্ড ষ্টুডিও প্রোঃ মোঃ সাদ্দাম হোসেন : electronics\n","দান স্টোর প্রোঃ মোঃ শরিফুল ইসলাম : grocery\n","ব্যবসা : distributororwholesale\n","enterprise powertek : distributororwholesale\n","foods : distributororwholesale\n","হাতীবান্ধা : distributororwholesale\n","for surveyar but others not for company try to job : distributororwholesale\n","pharma ltd : pharmacy\n","টেলিকম : mfsmobilerecharge\n","enterprise : distributororwholesale\n","b fashion : clothstore\n","দোকান : grocery\n","ষ্টোর : grocery\n","কম্পিউটার : electronics\n","হোসেন online instant recharge point : mfsmobilerecharge\n","ghosh son s : grocery\n","store : grocery\n","রানা টেলিকম : mfsmobilerecharge\n","বস্ত্রালয় : clothstore\n","agro এ ওয়ান ফিড এন্ড চিকস্ : distributororwholesale\n","বাবার দোয়া এন্টারপ্রাইজ : grocery\n","ভিজুয়্যল : grocery\n","জিন্স ফ্যাশন : clothstore\n","monirul islam : distributororwholesale\n","dso sohel : mfsmobilerecharge\n","point : clothstore\n","স্টোর : grocery\n","pharmacey ডাঃফরিদুল ইসলাম : pharmacy\n","আল আমিন ভ্যারাইটিস ষ্টোর : grocery\n","ভ্যারাইটিজ স্টোর মোঃচাঁদ আলী বিশ্বাস : grocery\n","power eletric shibgong point : electronics\n","store : grocery\n","শাহ ডিপার্টমেন্ট ষ্টোর : grocery\n","stura : grocery\n","আমিন : grocery\n","সুফিয়া ট্রেডার্স : distributororwholesale\n","জানি তুমি আমার হবে না : mfsmobilerecharge\n","টার্গেট রাজাপুর বাজার : electronics\n","poltio faram : motorrepair\n","islam : grocery\n","ইলেকট্রনিক্স : electronics\n","এন্টারপ্রাইজ থানা রোড নাসিরনগর : hardware\n","store : grocery\n","ভ্যারাইটিস পুলেরহাট বাজার : grocery\n","ট্রেড সেন্টার : distributororwholesale\n","খান : grocery\n","ফার্মেসী : pharmacy\n","store : grocery\n","ফার্মেসি : pharmacy\n","lab : pharmacy\n","স্টোর : grocery\n","screen print : clothstore\n","ডিপার্টমেন্টাল স্টোর : grocery\n","institute : electronics\n","বাই : grocery\n","হোমিও হল : pharmacy\n","টেলিকক : mfsmobilerecharge\n","এন্টারপ্রাইজ : distributororwholesale\n","stor : grocery\n","টেইলারস শিন শিন রোট : tailors\n","ডিজিটাল স্টুডিও এন্ড কসমেটিকস্ : cosmetics\n","হাসান : grocery\n","হক : grocery\n","stor : grocery\n","ষোটর : grocery\n","ma entarprise : distributororwholesale\n","ইস্টোর : grocery\n","traders : distributororwholesale\n","\n","[[ True False False ... False  True False]\n"," [False False False ... False False False]\n"," [False  True  True ...  True False  True]\n"," ...\n"," [False False False ... False False False]\n"," [ True False False ... False  True False]\n"," [False False False ... False False False]]\n"]}]},{"cell_type":"code","source":["# # save model and architecture to single file\n","# model.save(\"/content/drive/MyDrive/Colab Notebooks/shopname_model_15_cls.h5\")\n","# print(\"Saved model to disk\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYlps-XnijUx","executionInfo":{"status":"ok","timestamp":1667889250673,"user_tz":-360,"elapsed":1025,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}},"outputId":"e8db583a-ac8b-4b57-98cb-5fea0c58158e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved model to disk\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oOzSKagLFPz8","executionInfo":{"status":"ok","timestamp":1667880666667,"user_tz":-360,"elapsed":10,"user":{"displayName":"Shithi Maitra","userId":"01287562705842979191"}}},"execution_count":19,"outputs":[]}]}